{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.060842Z",
     "start_time": "2019-05-14T23:57:20.053165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('./shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.077596Z",
     "start_time": "2019-05-14T23:57:20.064808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to one-hot tensor.\n",
    "def seq_to_onehot(seq):\n",
    "    tensor = torch.zeros(len(seq), 1, n_chars) \n",
    "    # Shape of the tensor:\n",
    "    #     (sequence length, batch size, classes)\n",
    "    # Here we use batch size = 1 and classes = number of unique characters.\n",
    "    for t, char in enumerate(seq):\n",
    "        index = all_chars.index(char)\n",
    "        tensor[t][0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), 1)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_onehot(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]).long() # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.437344Z",
     "start_time": "2019-05-14T23:57:20.131573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (func1): RNNCell(100, 1000)\n",
       "  (func2): Linear(in_features=1000, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Initialization.\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size  = n_chars   # Input size: Number of unique chars.\n",
    "        self.hidden_size = 1000       # Hidden size: 100.\n",
    "        self.output_size = n_chars   # Output size: Number of unique chars.\n",
    "        \n",
    "        self.func1 = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "        self.func2 = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\" Forward function.\n",
    "              input:  One-hot input. It refers to the x_t in homework write-up.\n",
    "              hidden: Previous hidden state. It refers to the h_{t-1}.\n",
    "            Returns (output, hidden) where output refers to y_t and \n",
    "                     hidden refers to h_t.\n",
    "        \"\"\"\n",
    "        # Forward function.\n",
    "        hidden = self.func1(input, hidden)\n",
    "        output = self.func2(hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initial hidden state.\n",
    "        # 1 means batch size = 1.\n",
    "        return torch.zeros(1, self.hidden_size).to(device) \n",
    "    \n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Step and Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.449539Z",
     "start_time": "2019-05-14T23:57:22.440333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training step function.\n",
    "def train_step(net, opt, input, target):\n",
    "    \"\"\" Training step.\n",
    "        net:    The network instance.\n",
    "        opt:    The optimizer instance.\n",
    "        input:  Input tensor.  Shape: [seq_len, 1, n_chars].\n",
    "        target: Target tensor. Shape: [seq_len, 1].\n",
    "    \"\"\"\n",
    "    seq_len = input.shape[0]    # Get the sequence length of current input.\n",
    "    hidden = net.init_hidden()  # Initial hidden state.\n",
    "    net.zero_grad()             # Clear the gradient.\n",
    "    loss = 0                    # Initial loss.\n",
    "\n",
    "    for t in range(seq_len):    # For each one in the input sequence.\n",
    "        output, hidden = net(input[t], hidden)\n",
    "        loss += loss_func(output, target[t])\n",
    "\n",
    "    loss.backward()             # Backward. \n",
    "    opt.step()                  # Update the weights.\n",
    "\n",
    "    return loss / seq_len       # Return the average loss w.r.t sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:36.378318Z",
     "start_time": "2019-05-15T03:10:36.366394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation step function.\n",
    "def eval_step(net, init_seq='W', predicted_len=100):\n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden        = net.init_hidden()\n",
    "    init_input    = seq_to_onehot(init_seq).to(device)\n",
    "    predicted_seq = init_seq\n",
    "\n",
    "    # Use initial string to \"build up\" hidden state.\n",
    "    for t in range(len(init_seq) - 1):\n",
    "        output, hidden = net(init_input[t], hidden)\n",
    "        \n",
    "    # Set current input as the last character of the initial string.\n",
    "    input = init_input[-1]\n",
    "    \n",
    "    # Predict more characters after the initial string.\n",
    "    for t in range(predicted_len):\n",
    "        # Get the current output and hidden state.\n",
    "        output, hidden = net(input, hidden)\n",
    "        \n",
    "        # Sample from the output as a multinomial distribution.\n",
    "        predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "        \n",
    "        # Add predicted character to the sequence and use it as next input.\n",
    "        predicted_char  = all_chars[predicted_index]\n",
    "        predicted_seq  += predicted_char\n",
    "        \n",
    "        # Use the predicted character to generate the input of next round.\n",
    "        input = seq_to_onehot(predicted_char)[0].to(device)\n",
    "\n",
    "    return predicted_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.556497Z",
     "start_time": "2019-05-14T23:57:22.478732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:99/12300 loss:3.7592949867248535\n",
      "generated sequence: Wl@&/;&\n",
      "e,eeieEIaTh vhersd.osTaru l\n",
      "f|tlA \n",
      "iem-sbddgymd,'  wIaiRut  amhEe hlhaaf.hI\n",
      "n yN iino roe \n",
      "sn\n",
      "\n",
      "iter:199/12300 loss:3.364504098892212\n",
      "generated sequence: Wqd+HA t reIrnnar.\n",
      "el a iae ohooryylhKalawiCmOtn yr Aheadramtaoe holenl. \n",
      "ayeOe  tTardtno tyLlu\n",
      "ikIoy\n",
      "\n",
      "iter:299/12300 loss:3.3826065063476562\n",
      "generated sequence: W'g\n",
      " eN ,o kewuKt toreg.,nehoi erlk eadiR\n",
      "a,i,syeuAo  snhi\n",
      "Tetpbyoacn;T,ihhr  aluto\n",
      "lltun  .,as v.i,p\n",
      "\n",
      "iter:399/12300 loss:3.37135910987854\n",
      "generated sequence: Wl\\-\"Rcd  i BbaohoOiiniF esoddew yiR tsw lUntoL \n",
      " Fenoss'e \n",
      "rdotil  h\n",
      "\n",
      "onhrete moo ue,i\n",
      " rwe S dp uro\n",
      "\n",
      "iter:499/12300 loss:3.330958127975464\n",
      "generated sequence: WQ9Ouhr,aapshon hAtudhdm:\n",
      "ints ad hgawuaqd  !hre  h\n",
      "o arfheerln giWndt o-altceedowr A\n",
      "ienom?,lahm\n",
      "n  \n",
      "\n",
      "iter:599/12300 loss:3.352985143661499\n",
      "generated sequence: WTUCfafnmr, re ddcfI r E gt: os!MdeaNyhb ydhhe  ,,rhRme  teshe r ho aev e .rhmto  eWai u dhwtTEaeL i\n",
      "\n",
      "\n",
      "iter:699/12300 loss:3.3276519775390625\n",
      "generated sequence: WaIGee\n",
      "rrgd  reu   \n",
      "o ;hhsC wfre\n",
      "aeea lo'inoh,hn aogLvGomee Oero  AeiEho oenm rvsyaul  tws oPlhlvl \n",
      "d\n",
      "\n",
      "iter:799/12300 loss:3.3215432167053223\n",
      "generated sequence: WIo.tpotnnO wI  sins arr etwale o oa'o tse  dasnly l pehttA\n",
      "easob dB   ee ufm lf ldeddleMgnddi\n",
      "\n",
      " ieyB\n",
      "\n",
      "iter:899/12300 loss:3.311587333679199\n",
      "generated sequence: W.Zn da ;lolucww,,rlrh sleFibro,l.mcd 'yelseateh,agretiintYhe tI poauonihLa : I a a l n:uf Yp\n",
      "a\n",
      "uelal\n",
      "\n",
      "iter:999/12300 loss:3.306001901626587\n",
      "generated sequence: W$oDP ObTs hsSnrNof rEddin o cnk aunpmn tiebaels aw\n",
      "tul:\n",
      "oNe h\n",
      "r\n",
      " EclodogmnrdySb pWa ,aom Er \n",
      "h o\n",
      "tpt\n",
      "\n",
      "iter:1099/12300 loss:3.301987648010254\n",
      "generated sequence: WEsEdii h 'r ea ' oE Eulvhsi\n",
      "\n",
      "anvslvtorha\n",
      "rienoeenhmst,anab an hl As raealInsotd efr\n",
      "uiS'btoo,wy edwa\n",
      "\n",
      "iter:1199/12300 loss:3.2974963188171387\n",
      "generated sequence: WSGvrcta ec idn!laotfosjo   dr\n",
      "oinW ia .ssT  snhze AEhEebleecao amThe n kmtHs s sse n\n",
      "Oe u'e,shsor tr\n",
      "\n",
      "iter:1299/12300 loss:3.3335652351379395\n",
      "generated sequence: W(od,Olteoa\n",
      "faoasaoi\n",
      "\n",
      "taI\n",
      ".hrhhpnotlhas:.t u tdHin mho'  oea fhuth 'sa oOh; ie rd vui jles  oW!mK.mdo\n",
      "\n",
      "iter:1399/12300 loss:3.3198776245117188\n",
      "generated sequence: W4NMieemn . not tes?to herci,usyNh  weet a onsrtrnroowopi;cogP gafen Aoeenewree F,etalomn ot o'hfm  d\n",
      "\n",
      "iter:1499/12300 loss:3.307614326477051\n",
      "generated sequence: Wdg a\n",
      "sAtyortPa ae\n",
      "nRskv yr\n",
      "tlso\n",
      ",cyuh nDeokueae aEy igihee mYshdAh- cNteeom oor netomolnonmunoeei ,i\n",
      "\n",
      "iter:1599/12300 loss:3.2810628414154053\n",
      "generated sequence: WbulgyTsit wsohno,e,isnei,ilo oo ao,si.intau e a teoe nl r piodfflhtv elr\n",
      ",i.rehliLeCrlhhrcm:tHltie \n",
      "\n",
      "\n",
      "iter:1699/12300 loss:3.30094313621521\n",
      "generated sequence: Wymc'i nleeYSh'h.dttnnnhp ar owseR,l erwwva loegipsobao ff eteOvyacreeni adstwitrNtyH snls.taet yedns\n",
      "\n",
      "iter:1799/12300 loss:3.2851529121398926\n",
      "generated sequence: WY-s\n",
      "frgshet:sasa!esbsosh;aioa NccPtudeaD e miest h  snror anottIiikI ,mmn sWLiheiah aie;e nsiaenpei\n",
      "\n",
      "\n",
      "iter:1899/12300 loss:3.2662107944488525\n",
      "generated sequence: W?uo  gksh tp\n",
      " Fite Phoottueaicahs aOr   gfau aT\n",
      "Ihshlh atisTVhrtnd p\n",
      " b o\n",
      "eGwt\n",
      "fyso\n",
      "ehel atayovs vhS\n",
      "\n",
      "iter:1999/12300 loss:3.236375331878662\n",
      "generated sequence: W\\}IheloEidroe:heyemmosi\n",
      "I  rrBhars\n",
      "H wmIloh:eovosito anten ;n ewd o:hAnh loheht\n",
      "IAIehac  arIWe\n",
      "lo Ho\n",
      "\n",
      "iter:2099/12300 loss:3.265288829803467\n",
      "generated sequence: W8VIdegeisii ooohO\n",
      "eiAe EmA  es othlr har\n",
      "  eIIssrlnPouctueo CineeetRrrao.ot\n",
      "e aB aeEb oeaafb  a.hrC'\n",
      "\n",
      "iter:2199/12300 loss:3.2151310443878174\n",
      "generated sequence: W*im  Myt rhuu\n",
      "\n",
      "wiahhhoftbA\n",
      "e t,oo h  DohR ohuhas\n",
      "dln\n",
      "esv bhI ,ra cyu  ibfoiYtifroed\n",
      "drCTr h O\n",
      "ihddoI\n",
      "\n",
      "iter:2299/12300 loss:3.249119520187378\n",
      "generated sequence: W\f",
      "jouw dodeeSwyrlPh\n",
      "ll py tar eBwun MnfgdrnBAelpruFNoss onadoeaabrAigmu'coO\n",
      " nhreukfse\n",
      "sActdd'h, ns \n",
      "\n",
      "\n",
      "iter:2399/12300 loss:3.2185115814208984\n",
      "generated sequence: W\u000b",
      "taenic \n",
      ":  nud i,sh! hCeuo u.ioAl ehhEnn V,E\n",
      "n k er ahslsnsky eZS oowreit:or\n",
      " puuneBllC hloieaFeefG\n",
      "\n",
      "iter:2499/12300 loss:3.2131757736206055\n",
      "generated sequence: WFSis ,i\n",
      "eoncera immnehGaTeah himfroo..dFc feTt,rcwthn :ea.pmnfceeret dnfbhd l soth u\n",
      "e em boatoyOvee\n",
      "\n",
      "iter:2599/12300 loss:3.215672492980957\n",
      "generated sequence: W:)!jtt\n",
      "emli\n",
      " hrssrs mrt uae,dv.fmhenyrto  tscbtrs;deO ohfieotroleI aotpmalw lnemNrsycwy:sl rAYw.bm:h\n",
      "\n",
      "iter:2699/12300 loss:3.1566162109375\n",
      "generated sequence: WT- euGrie rra hafsts YupEorfTdhotd mcrrgioTs Ck epwpleipo rscneehleraueB aEl ehyhlya hihshi tht ,Il \n",
      "\n",
      "iter:3299/12300 loss:3.1088273525238037\n",
      "generated sequence: Wpotle\n",
      "pwbrhsr\n",
      "trIt \n",
      "nnerisL \n",
      "iisrMhuefAdghbu iaesse, Ihe TereEeMbeey!wao  aod  lalhse yorn\n",
      "sen Rthri\n",
      "\n",
      "iter:3399/12300 loss:3.0918898582458496\n",
      "generated sequence: WmOdc hhtnhnn oieh s holnt n ttmtkt Oo eod ogi stei oepe vum\n",
      "h,a dMAt raryetomhI toae mod .heeweybI r\n",
      "\n",
      "iter:3499/12300 loss:3.0693771839141846\n",
      "generated sequence: WEh,at mriKhm Ie hhaNs.'shn\n",
      " ohtt cod tn\n",
      "m hAurWre \n",
      "u.hw toil reEg\n",
      "ahn.oet toly tos ons,rISoercoOc.pp\n",
      "\n",
      "iter:3599/12300 loss:3.0329675674438477\n",
      "generated sequence: We roirsIoo, He\n",
      " ,ieoe iaomsbh\n",
      "efrEi ;I  viy  hivds ics hn vE doi  uphT ledo\n",
      " eint'gbti sis\n",
      "uaice Ugc\n",
      "\n",
      "iter:3699/12300 loss:3.0660924911499023\n",
      "generated sequence: W*sNeeeT oy bh goik ieghcwdr n bchb eth wtA a Yace toaee\n",
      " nsI :olh m  imtn   trslrl p tho uEdr\n",
      "hrl io\n",
      "\n",
      "iter:3799/12300 loss:3.0405802726745605\n",
      "generated sequence: Wa,eshhoe noCaue\n",
      "VoifcSw ow nomith r urmh me Toy \n",
      "art\n",
      " aeN:h eff tt Iloait dh  hi e tauh ,ohe yeu\n",
      " aw\n",
      "\n",
      "iter:3899/12300 loss:3.0399169921875\n",
      "generated sequence: W;ktueulmAo?\n",
      "to   tyttvrta'  l,itI rd e r tre,a sessaeurta dila,wb\n",
      "thae eooraim tIvlc te dt . labie n\n",
      "\n",
      "iter:3999/12300 loss:3.024434804916382\n",
      "generated sequence: WLtcs  tentynesise IeeK Lbio yGrsdtTsn; ael \n",
      "uDe \n",
      "onIiyeib'  o aehled couc: fit,Esl' doldo\n",
      "nWnnern RH\n",
      "\n",
      "iter:4099/12300 loss:2.987774610519409\n",
      "generated sequence: Wppunea\n",
      "w cofC, uol to'bEonrt\n",
      "N nslhwigesw,eet hide iir:widC caspl hfslrhesrcOaU\n",
      "tarey, y;tia osT,to,\n",
      "\n",
      "iter:4199/12300 loss:2.983072519302368\n",
      "generated sequence: WrtrrdWmemt rmsAttua\n",
      "le eca dhepnes\n",
      "\n",
      "apw iostees mta ei edetsahabl  irwdnshsee\n",
      "oea meo boretn ne dtar\n",
      "\n",
      "iter:4299/12300 loss:3.003340721130371\n",
      "generated sequence: Werbithg \n",
      "o,lyfd:go\n",
      "!gWi eg;ntracy\n",
      "d; yo:t ehes  y:een  eavygnun\n",
      "ige,eanhe boo d phSdee doc otl Witer\n",
      "\n",
      "iter:4399/12300 loss:2.9755635261535645\n",
      "generated sequence: WzBshevrKt:or deI,  onoy blkacvoomrth: thsattr laye ohes rouny\n",
      " kw  ho me  hnu air yo\n",
      "sdKs no aypgrns\n",
      "\n",
      "iter:4499/12300 loss:2.9753761291503906\n",
      "generated sequence: W~Ttgw.rthrdaan\n",
      "\n",
      "u\n",
      "s\n",
      "\n",
      "n-\n",
      "  twke lhtdu \n",
      "LtuitemoLtN'uA :tlno Te lhnTiswI wo resshnrs ooatu aft enu\n",
      "ehe\n",
      "\n",
      "iter:4599/12300 loss:2.9714415073394775\n",
      "generated sequence: WSEnot oonn\n",
      "ynlh\n",
      "\n",
      "ri bOr  hllhgso Iothdsdnsl:tgoe\n",
      "in\n",
      "tDzn GsiCntw \n",
      "w iht ti,nm' \n",
      "aac tl toecaw o seao\n",
      "\n",
      "iter:4699/12300 loss:2.9668831825256348\n",
      "generated sequence: WGn.ew hr  nr loa, \n",
      "bgowf chnmEHsA  hot bhay fnrs the teeteA\n",
      "\n",
      "zicn Efy thal teniPisila ho  aessfeles \n",
      "\n",
      "iter:4799/12300 loss:2.9475948810577393\n",
      "generated sequence: W#enrueane\n",
      "tSI eaideibnr Hoame,Iwper:o.w eog ,ogod dsolthyFhammg,e\n",
      "nW pofne:lamyou\n",
      "whene h'Fanthd unn\n",
      "\n",
      "iter:4899/12300 loss:2.927466869354248\n",
      "generated sequence: Wie ih,ca\n",
      "s\n",
      "soruslaut\n",
      "; ht ser isodhe  yental,wmveli d teore hoe catthe isn .il\n",
      "st uon esru yhonyyiFI\n",
      "\n",
      "iter:4999/12300 loss:2.940239191055298\n",
      "generated sequence: Wivyt\n",
      "c ;ye nae wort toir\n",
      " Aod weu\n",
      "tsthhsO\n",
      " \n",
      "harefdeenas-eB eh doe, Isuh  armc to,  hoit.venk\n",
      "E:nj: n\n",
      "\n",
      "iter:5099/12300 loss:2.9191904067993164\n",
      "generated sequence: Wys, amefh? sIrn llr thalt towvot ya drdhgew\n",
      " or tem \n",
      "oo ,ole bh l\n",
      "ke yher,t yo  ou lhelhd \n",
      "eayo ho. \n",
      "\n",
      "iter:5199/12300 loss:2.907782554626465\n",
      "generated sequence: W>st  ue ohls\n",
      "eheet tArl f. toabeU!t Biodaa rho  eus lim  sa teua lenYr :S da tl tm rnnvyit  rWeetcc.\n",
      "\n",
      "iter:5299/12300 loss:2.8986382484436035\n",
      "generated sequence: WZ:re lhrmt lpns ycudent \n",
      "t eawnit so ee the shr eoitf \n",
      "oauc uy soos.h ekstesfncseesgoMnml lentpr\n",
      "duy\n",
      "\n",
      "iter:5399/12300 loss:2.9055473804473877\n",
      "generated sequence: WCya linl wow hot Se afddI\n",
      "noxs\n",
      "ImToy',has aheth.l!' dnotegs\n",
      "khleyL\n",
      "OoH ooal  ho d,ryw nor tume be co\n",
      "\n",
      "iter:5499/12300 loss:2.8567285537719727\n",
      "generated sequence: W(k uhnml \n",
      "intd FiiIt tavl tel,,\n",
      ",a mee thel .e peyfb a. th mosB tyek ayt e' haoc wo bY'cc aie an? \n",
      "o\n",
      "\n",
      "iter:5599/12300 loss:2.8723182678222656\n",
      "generated sequence: W-rAsessgDU rmvc;o,s hAfrtf ilrntot:atACHit aiir Totuse wor Afha ye estho\n",
      "ffGthew lyast :o has .ekneY\n",
      "\n",
      "iter:5699/12300 loss:2.900543451309204\n",
      "generated sequence: W\t? nntsoe riioie tpruhu dw sot;\n",
      "rl eim t satraneza!\n",
      "tJ ervnkrly ohs eay'ai sfuuseaems\n",
      "daN ekstu nofe\n",
      "\n",
      "iter:5799/12300 loss:2.901118040084839\n",
      "generated sequence: WgsAra dorsmdrhiL wh.t ml coat noee fs unlufe no hhie. so goukcf''.e \n",
      "yssei\n",
      " ooorwm\n",
      ", vaudhait o  ihd\n",
      "\n",
      "iter:5899/12300 loss:2.8548030853271484\n",
      "generated sequence: W\\er \n",
      " onC\n",
      "enS EWTr SIIlfit s\n",
      "dWMnmnsCes :os ktir,pirscNew tO thlctto,  cot,Feniep.\n",
      "IaeUi\n",
      "I o\n",
      " IoucfW\n",
      "\n",
      "iter:5999/12300 loss:2.8429789543151855\n",
      "generated sequence: WZudu yauet whonvd peftaBing bowltcert oo ihawi,ate p onetadelhTs ths peos she  aou ninh \n",
      "Mea ei hi l\n",
      "\n",
      "iter:6099/12300 loss:2.8493239879608154\n",
      "generated sequence: W\n",
      "nhei.\n",
      "\n",
      "p So leftps ba teoclwed eoro hntd tnene:' nhe m me kois\n",
      "efwI rotorit let dtneaktt,bhoO \n",
      "arhd\n",
      "\n",
      "iter:6199/12300 loss:2.8434464931488037\n",
      "generated sequence: WMn;clt,nfne te aaah rr eera whr tiwg goim!re\n",
      " no,inn uot rote\n",
      "\n",
      "\n",
      "Rn ho d, wHd sruvIpwsn aid woae :ocr\n",
      "\n",
      "iter:6299/12300 loss:2.827446222305298\n",
      "generated sequence: WQs, wetcanets  lode hhveeh Lunmlssehs s,ltitoy ahlt ere aa ee bwrae eot tylriano lBtiink InomniPrett\n",
      "\n",
      "iter:6399/12300 loss:2.840571165084839\n",
      "generated sequence: W9nw th!dC;hPas IhrLd,eEse Ioapv\n",
      "k?smaKdb\n",
      "t\n",
      "ihHsTc-ssOd ho Iam;d,rsKa\n",
      " yisewn:r norhls haee by  anefh\n",
      "\n",
      "iter:6499/12300 loss:2.8199522495269775\n",
      "generated sequence: Wzan  he te tog lhmhe tho baYm?\n",
      "\n",
      "r5Ko Nxrbls:edeshe  \n",
      "aar hotrtt\n",
      "ve thoy th ny Mo  aolde\n",
      "to RluN nogd\n",
      "\n",
      "iter:6599/12300 loss:2.819549798965454\n",
      "generated sequence: WvN asymsof htr, fubK wods, tndlmh, ;ad  he basfr\n",
      "sRs tNoal cWadnaloaf doehetrIt normal kfao darond w\n",
      "\n",
      "iter:6699/12300 loss:2.8294291496276855\n",
      "generated sequence: WTois k!mespN\n",
      " saaruLNet\n",
      ":ndtoun sand hhan, thut arb,gtiW 'rntg yawdd ,ndnyphhly we rad ho,vbun 'hi k\n",
      "\n",
      "iter:6799/12300 loss:2.815007209777832\n",
      "generated sequence: Wbo\n",
      "nhHnjtI\n",
      "r\n",
      ",rNrt Ile de nordzn vfk midouh Lwwldr moobr,ty to rstooEnsSH Not Co airdmT\n",
      "e ta do\n",
      ";TA;\n",
      "\n",
      "iter:6899/12300 loss:2.7977535724639893\n",
      "generated sequence: W.agesrTt:epgw'kes neamypli hassouhd hitgsyeeto\n",
      "\n",
      "Ta taUrin-o: thinechy\n",
      "wAfby Yttbgdlsrw afre ma ,idha\n",
      "\n",
      "iter:6999/12300 loss:2.81278920173645\n",
      "generated sequence: W!in mft, aot arth\n",
      "tB,s w shhcagv efwwnhea\n",
      "b\n",
      "ngloen\n",
      "nobr yole aeenotle \n",
      "e thctsor hf thamef,bsork\n",
      "Nia\n",
      "\n",
      "iter:7099/12300 loss:2.784245252609253\n",
      "generated sequence: W%yi\n",
      "e,\n",
      "Lol\n",
      "He!OT'dhd eitie ;h gum piSb sanhe t, les sovuA \n",
      "mtsh \n",
      "Ta do eout tnenghuu-\n",
      " obb ehvaed uk\n",
      "\n",
      "iter:7199/12300 loss:2.7942450046539307\n",
      "generated sequence: WVua.\n",
      "tNVlIB !EV mh Toet bute nllpT.e\n",
      "ttnhtts ;hevdsuav htak no trev oa ce douer.nbph,Fm\n",
      "paui sar soa\n",
      "\n",
      "iter:7299/12300 loss:2.8095703125\n",
      "generated sequence: WrNs\n",
      "rrnEed even theedred areebn n wits, ahet.e Sosd gbnds;a;d whr ioe ry gai  aacito siaed\n",
      " hatoe ga\n",
      "\n",
      "iter:7399/12300 loss:2.787665605545044\n",
      "generated sequence: Wa nnecw\n",
      "ya yhrl,shewe dw noceis sriild thar ctp ourerenrn:tfimnm defbers Fhlpaee sarshi drel hhe.o D\n",
      "\n",
      "iter:7499/12300 loss:2.782303810119629\n",
      "generated sequence: Wks tin.ao be boatntnthend.\n",
      "\n",
      "WOlo;r:\n",
      "\n",
      "oo  uoouw anaky vo gyaha  toieh pet do noteg.\n",
      "dO, Ahe tor welrr\n",
      "\n",
      "iter:7599/12300 loss:2.7741453647613525\n",
      "generated sequence: Wtfrl aIr tteOcSTeS :erEsrdshemb  htaat had cerccmy:h nanhom Ibttans wraggeeminou dijotsTeOyhot aesh\n",
      "\n",
      "\n",
      "iter:7699/12300 loss:2.772412061691284\n",
      "generated sequence: Wrai onmr ayFLDu sa,h  eme rn ye toaf KiF  ors ?oom: wo ias\n",
      "\n",
      "felr Couot ye iotnm\n",
      "w\n",
      "diot.eIIsAs medbuj\n",
      "\n",
      "iter:7799/12300 loss:2.7607154846191406\n",
      "generated sequence: Wa dha ro.n\n",
      "lMLItOa\n",
      ":\n",
      "Doy 'syity weet\n",
      "tyuol\n",
      "\n",
      "cOLRhD\n",
      "PRE:\n",
      "Ahod toe,\n",
      "\n",
      "oit e whntm\n",
      "-an, frco\n",
      "\n",
      ",ote t ult\n",
      "\n",
      "iter:7899/12300 loss:2.7539708614349365\n",
      "generated sequence: WCi\n",
      "glflL\n",
      "othYrlur roab, tr koLes\n",
      "hTl tiae w te ts tteu yo riifemgn \n",
      "atoc mh whe suererd\n",
      "nh  har ,esr\n",
      "\n",
      "iter:7999/12300 loss:2.7431559562683105\n",
      "generated sequence: WBUlTKw\n",
      "oRIUt:niou ayvincs uoatl. \n",
      "arioh thin  tremkrIo, iias rfocd, oud,IRt st uhetnf,sb  ot soae l \n",
      "\n",
      "iter:8099/12300 loss:2.738553524017334\n",
      "generated sequence: Wr,s perin\n",
      " hitd, rh fpml th\n",
      "isR tToesOtnnas hide sss dcdr aoua,\n",
      "ao: io  aollR! nhOm \n",
      "arem,rMnfs doth\n",
      "\n",
      "iter:8199/12300 loss:2.736546516418457\n",
      "generated sequence: Wd\n",
      "hrvns th soenetr sestmegt apd pivuKivee,\n",
      "Fhd, Tias \n",
      "enst anl t!n toentfisr ice.rhadgnf yeni tteh\n",
      "d\n",
      "\n",
      "iter:8299/12300 loss:2.7576980590820312\n",
      "generated sequence: Wg.tea. \n",
      "orTlp vanwest aosnilc, thm mot:\n",
      "tlixininoC so rr uog Na Aut oovnn,\n",
      "ao erde myehg wulcwB,umhi\n",
      "\n",
      "iter:8399/12300 loss:2.728445053100586\n",
      "generated sequence: W!,;\n",
      "ooag Thtsad \n",
      "oo d uf cpalt eTithel hdlLsh, :ele ththeb hi daisle.\n",
      "hhT Ehrk ohl  eonemWs\n",
      " lrrsrre\n",
      "\n",
      "iter:8499/12300 loss:2.7351861000061035\n",
      "generated sequence: WtjLddS titf seu kesz\n",
      ";e?:RtI he ayo h yrveics venlint Mncrys bod snd iathd pouvus . dadl h yseot sly\n",
      "\n",
      "iter:8599/12300 loss:2.7005889415740967\n",
      "generated sequence: WPeg nhu fograsl narserdiRd :it .uut\n",
      "lt noe 'te ,eua, ae rhvl rarp unsll vL die.t eh gn eyat\n",
      "dtlo! ve\n",
      "\n",
      "iter:8699/12300 loss:2.7001471519470215\n",
      "generated sequence: Wa noode viwes hepc ye hhet thio :n, heat.en\n",
      "I\n",
      "f\n",
      "Ae NoS IAUtGy atI andIl,,inat\n",
      " fakh yl lhdb mtlet\n",
      "\n",
      "w\n",
      "\n",
      "iter:8799/12300 loss:2.704197645187378\n",
      "generated sequence: Wdk\n",
      "cAiG Iekus oo mosn tiaJ harh sat, -onht\n",
      "Chpmgcr thoy tadta\n",
      "fBondpsNns aUenl,,nay  toe theet. uln \n",
      "\n",
      "iter:8899/12300 loss:2.7053210735321045\n",
      "generated sequence: WgYnnr\n",
      "I WLhNld ,pvers\n",
      "\n",
      "It O ihisgtW\n",
      "sfrIni eo tilbh;nI,:\n",
      "Sive bie bhiir lo deetuy whnr t ala.\n",
      "\n",
      "nABnU\n",
      "\n",
      "iter:8999/12300 loss:2.700770139694214\n",
      "generated sequence: Wtlid ,ik mereoeei\n",
      "t  aoiik aet hussam' since that'\n",
      "heSssea, ou ,yuy;;\n",
      "fe teef 'ivicf!rjjniUd fao sua\n",
      "\n",
      "iter:9099/12300 loss:2.7214903831481934\n",
      "generated sequence: Wana sor\n",
      "unfOw te allao Iy hHc cuue th te moueh se.vYr hrncl, fawe rar th meo whin brtuind \n",
      "aie aice.\n",
      "\n",
      "iter:9199/12300 loss:2.662790536880493\n",
      "generated sequence: Wo con mavitra enwtywcrmehea ;iKer,K!nbec\n",
      "oug ihmesm Mds\n",
      "IhT EifenTy Bae shit d ceurhy cors thm the t\n",
      "\n",
      "iter:9299/12300 loss:2.6916072368621826\n",
      "generated sequence: WRn founriun.\n",
      "\n",
      "MoouW\n",
      "r:':haoo aas bfeptir? te toiditoN \n",
      "ora hi lsafqp Weyig! !I l thk piow eryJ\n",
      " ueUy\n",
      "\n",
      "iter:9399/12300 loss:2.6856536865234375\n",
      "generated sequence: WdF\n",
      "kb thalon,tWil tpmyecrepu yhevt\n",
      "oCgsyen aithi det-e w iu, oad\n",
      "oiue  tifwum coI mosh\n",
      "wpv, madt aru\n",
      "\n",
      "iter:9499/12300 loss:2.69467830657959\n",
      "generated sequence: Wvvetnud yfoehEeTTot io hem semThd dore fifhI dhs ercn\n",
      "duBU \n",
      "Ei;: fu eGeLtG nouce.e\n",
      "SfuUA do :in  wiu\n",
      "\n",
      "iter:9599/12300 loss:2.683509111404419\n",
      "generated sequence: Wdc tnttr gen,ct  haue \n",
      "fL?ev a.I\n",
      "pIwcos ioe  loraritS\n",
      "V untnwesm ne the the.\n",
      "ma'f aBa hast.yh\n",
      "u aie \n",
      "\n",
      "iter:9699/12300 loss:2.7069766521453857\n",
      "generated sequence: Wls IhYle ins inces ioe sh br toe ci eat'\n",
      " hou ao merg .itd, hom le ynsh seskom:\n",
      "oh ler thrlw ot k.um\n",
      "\n",
      "iter:9799/12300 loss:2.6676743030548096\n",
      "generated sequence: Win ieueBth that yad giyemI\n",
      "\n",
      "TWmrret ,o heo h ttnsate  yonBpeCg\n",
      "n\n",
      "o teern- hace gerl wnle liepshru, ,\n",
      "\n",
      "iter:9899/12300 loss:2.6710429191589355\n",
      "generated sequence: Ws \n",
      "f bElnnI\n",
      "\n",
      "TPNuNTcBUyORC \n",
      "AeAaOHIEy\n",
      "HWdhrNsssLt th nhebs wemh aurfln,\n",
      ":Ial hhisli,;\n",
      "araty CDth ma \n",
      "\n",
      "iter:9999/12300 loss:2.657644033432007\n",
      "generated sequence: Wbntheh\n",
      "\n",
      "o, nra:uah gbotay enaIL\n",
      "\n",
      "ouar tays wle sunhe ctetld thasd as kosth's\n",
      "oid;en oh thice soriwfe\n",
      "\n",
      "iter:10099/12300 loss:2.6459503173828125\n",
      "generated sequence: WSsreCwer acear,n;ntns br io owvme,\n",
      "\n",
      "sEIAeI;\n",
      "'gN:IyLw\n",
      "IrHI sIth ln nhee ,at, ip phreel mns;iwim tNt p\n",
      "\n",
      "iter:10199/12300 loss:2.654132604598999\n",
      "generated sequence: WI ll aw cs thy kisg t itecn.RgOs Pedrrfnne, tho lodmfu, plleJ Oome\n",
      "yy Nrse ceydithim \n",
      "Isils Pel ola \n",
      "\n",
      "iter:10299/12300 loss:2.6593284606933594\n",
      "generated sequence: WHbot\n",
      "e\n",
      "ZIRER sh HosHure thil anahol 'sr;thtsi\n",
      " oike d sik en irs r iou alwts arihos phowe de sa\n",
      "ypdA\n",
      "\n",
      "iter:10399/12300 loss:2.6571590900421143\n",
      "generated sequence: Wbg\n",
      "\n",
      "e:lKo tia, wiw oarkhde iytaria\n",
      ",\n",
      " itaa' strthe, mo hr toaca.d\n",
      "\n",
      "hIR:NEr:BTRaUrnWlslndut gor keeya\n",
      "\n",
      "iter:10499/12300 loss:2.6898796558380127\n",
      "generated sequence: Wi- oe cor omber giwesoH Cartdent'uW\n",
      "\n",
      "kP'tut te thv ilen,\n",
      "sot withe \n",
      "oga serlmrt spweath:e 'oyar T!e \n",
      "\n",
      "iter:10599/12300 loss:2.652463674545288\n",
      "generated sequence: Wzouk; tai. Lhetcea peyn aeen:\n",
      "kuapy rrheldibn,\n",
      "sil'  riel .aolnrs ouptokt dath cey oe wisuIud\n",
      "an:\n",
      "pe\n",
      "\n",
      "iter:10699/12300 loss:2.6518795490264893\n",
      "generated sequence: WN dhloc\n",
      "tham fhave m ohe tislnss,;i\n",
      "HdtSvoid Thaap s yerrea toion,\n",
      "a' the tbre hac woyc,,\n",
      "uure env v\n",
      "\n",
      "iter:10799/12300 loss:2.643035411834717\n",
      "generated sequence: WY ailef s. os thet er!t ilr wusee tooes'W the'piflasy ta sefn deaab \n",
      "he PocR arswfeg hiuy yei;, fele\n",
      "\n",
      "iter:10899/12300 loss:2.658640146255493\n",
      "generated sequence: W2lod sot anl; mR!lm fine havwerd uandaI\n",
      "\n",
      "yot taeb ead aLgmosLp\n",
      "the tengnut'ithe hanht nivnrr uou\n",
      "ao \n",
      "\n",
      "iter:10999/12300 loss:2.6501879692077637\n",
      "generated sequence: Whanis aevu\n",
      " BUerm bisl tas her tham\n",
      ":oTMe she, -hit her sy meotc\n",
      "TGe cis bhusl,gftn tap erem\n",
      "\n",
      "ErCyvI\n",
      "\n",
      "iter:11099/12300 loss:2.6327450275421143\n",
      "generated sequence: Wl:mm eik  aad dmacer  l mitl dithen: mom \n",
      "onavtNant mu shei har\n",
      " oup e,drclas'hnln thas, Lishesf ead\n",
      "\n",
      "iter:11199/12300 loss:2.6278162002563477\n",
      "generated sequence: W-,RWekthe soman.\n",
      "ST' thew:\n",
      "sedrifdsrWKy\n",
      " Rue yfmyamt\n",
      "IhE eeov tat  iyhy loimh fo dd uPme fil erog ne\n",
      "\n",
      "iter:11299/12300 loss:2.6262075901031494\n",
      "generated sequence: WROBAlAE,\n",
      "Na der lua soy !le codeeve\n",
      "IFLWnR Ie bomuet wce chrrHlrLfhe payt,\n",
      "Tha  ihin. \n",
      "hontte uoo oe\n",
      "\n",
      "iter:11399/12300 loss:2.623743772506714\n",
      "generated sequence: Ws, au  nu the :ees tc geopthin ansi hare nous iu moum:\n",
      "poe d deygiEg\n",
      "G\n",
      "YSlOSO Sy \n",
      "UtaNnId\n",
      ":IUo iued \n",
      "\n",
      "iter:11499/12300 loss:2.605703353881836\n",
      "generated sequence: Wngh shend rparmn tae il\n",
      "?rx; soamle Rut tou;laipsWy mlokw Fodygmu seagq yo goorsinn wein thlad.l\n",
      "ASt\n",
      "\n",
      "iter:11599/12300 loss:2.604710102081299\n",
      "generated sequence: WFw onte ther, ilii baaiith t, oor her'cEti soulm yeacf ta ma.ep\n",
      "billT ooe teeathars \n",
      "ohe, anlti\n",
      "\n",
      "ofc\n",
      "\n",
      "iter:11699/12300 loss:2.589691162109375\n",
      "generated sequence: Wue  aouy\n",
      "IH\n",
      "WetOI BiN ao:FtId Athevlt taou\n",
      "ind Ior me undfwjyv,s'swiiso\n",
      "\n",
      "outhe wh th gergeGro hy iy \n",
      "\n",
      "iter:11799/12300 loss:2.5858988761901855\n",
      "generated sequence: Wlu chy id lhotgin toe c, the care.\n",
      "txMsAISBYLe\n",
      "liIp\n",
      "hr vl llilhiy .\n",
      " apyaWe n ramesr thome kutle ;om\n",
      "\n",
      "iter:11899/12300 loss:2.604130268096924\n",
      "generated sequence: Ws, sep poaltu,W,:pt th thetruty\n",
      "n ahen son del lev\n",
      "ygasrh toulld\n",
      "ntaCr sRaulr\n",
      "rYmt Loved mimo\n",
      "rtiRt \n",
      "\n",
      "iter:11999/12300 loss:2.5894277095794678\n",
      "generated sequence: W\toe , shr youtn ostaas nor !ssene hy cou daait , :ithhtc;-anlcs man ne ailo d' thrblhlu,dbwie, fou l\n",
      "\n",
      "iter:12099/12300 loss:2.593546152114868\n",
      "generated sequence: W0iny :;lnhy therenoine Qhcue so, ny Iito\n",
      "yoU rodfrip.s\n",
      "By Iaehs eoc ooe bf ulesn 'u, bhar wirld mn l\n",
      "\n",
      "iter:12199/12300 loss:2.5861427783966064\n",
      "generated sequence: Wqnny nil lore .het you qr hhal.\n",
      "\n",
      "RM evsn:BUow Inncved\n",
      ", tooe boov y asrbbn seow Whels.rTne ser ia se\n",
      "\n",
      "iter:12299/12300 loss:2.604485034942627\n",
      "generated sequence: WPokmdnjte wouid boutd Kfr fe hod ispme 'o ,eto demind .areet,and 'plp\n",
      "iir bfwaverrhhtvinisiy'be eoug\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 12300  # Number of training iterations.\n",
    "print_iters = 100    # Number of iterations for each log printing.\n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "#################change optimizer ###############################\n",
    "opt       = torch.optim.Adadelta(net.parameters(), lr=0.005) \n",
    "#################change optimizer ###############################\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "count = 0\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    try:\n",
    "        input, target = get_input_and_target()            # Fetch input and target.\n",
    "    except: \n",
    "        count += 1\n",
    "        print(\"Illegal characters:\")\n",
    "        print(count)\n",
    "        continue\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    loss      = train_step(net, opt, input, target)   # Calculate the loss.\n",
    "    loss_sum += loss                                  # Accumulate the loss.\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(eval_step(net)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(eval_step(net, predicted_len=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = open(\"tanh_RNN_1000.npy\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [data.item() for data in all_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tanh_RNN_1000.npy\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"tanh_RNN_1000.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.load(\"tanh_RNN_1000.npy\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiment different plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.choice(100, 100)\n",
    "b = np.random.choice(100, 100)\n",
    "y = np.arange(100) #length of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.load(\"original_RNN.npy\"), label='RNN(Relu-100)')\n",
    "# plt.plot(np.load(\"tanh_RNN_tanh.npy\"), label='RNN(tanh)')\n",
    "# plt.plot(np.load(\"original_RNN_10.npy\"), label='RNN(Relu-10)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
